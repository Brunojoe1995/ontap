---
permalink: revert/task_things_to_verify_before_revert.html
sidebar: sidebar
keywords: ontap, revert, reversion, reverting, downgrade, downgrading, preparation
summary: 'Various configuration settings can impact cluster upgrade readiness.'
---
= System verifications to perform before you revert ONTAP
:icons: font
:imagesdir: ../media/

[.lead]
Before revert, you should verify your cluster health, storage health, and system time.  You should also delete any cluster jobs that are running and gracefully terminate any SMB sessions that are not continuously available.

== Verify cluster health

Before you revert cluster, you should verify that the nodes are healthy and eligible to participate in the cluster, and that the cluster is in quorum.

. Verify that the nodes in the cluster are online and are eligible to participate in the cluster: `cluster show`
+
----
cluster1::> cluster show
Node                  Health  Eligibility
--------------------- ------- ------------
node0                 true    true
node1                 true    true
----
+
If any node is unhealthy or ineligible, check EMS logs for errors and take corrective action.

. Set the privilege level to advanced: +
`set -privilege advanced`
+
Enter `y` to continue.

. Verify the configuration details for each RDB process.
 ** The relational database epoch and database epochs should match for each node.
 ** The per-ring quorum master should be the same for all nodes.
+
Note that each ring might have a different quorum master.
+
[cols=2*,options="header"]
|===
| To display this RDB process...| Enter this command...
a|
Management application
a|
`cluster ring show -unitname mgmt`
a|
Volume location database
a|
`cluster ring show -unitname vldb`
a|
Virtual-Interface manager
a|
`cluster ring show -unitname vifmgr`
a|
SAN management daemon
a|
`cluster ring show -unitname bcomd`
|===
This example shows the volume location database process:
+
----
cluster1::*> cluster ring show -unitname vldb
Node      UnitName Epoch    DB Epoch DB Trnxs Master    Online
--------- -------- -------- -------- -------- --------- ---------
node0     vldb     154      154      14847    node0     master
node1     vldb     154      154      14847    node0     secondary
node2     vldb     154      154      14847    node0     secondary
node3     vldb     154      154      14847    node0     secondary
4 entries were displayed.
----

. Return to the admin privilege level: +
`set -privilege admin`

. If you are operating in a SAN environment, verify that each node is in a SAN quorum: `event log show  -severity informational -message-name scsiblade.*`
+
The most recent scsiblade event message for each node should indicate that the scsi-blade is in quorum.
+
----
cluster1::*> event log show  -severity informational -message-name scsiblade.*
Time             Node       Severity       Event
---------------  ---------- -------------- ---------------------------
MM/DD/YYYY TIME  node0      INFORMATIONAL  scsiblade.in.quorum: The scsi-blade ...
MM/DD/YYYY TIME  node1      INFORMATIONAL  scsiblade.in.quorum: The scsi-blade ...
----

.Related information

link:../system-admin/index.html[System administration]

== Verify storage health

Before you revert a cluster, you should verify the status of your disks, aggregates, and volumes.

. Verify disk status:
+
[cols=2*,options="header"]
|===
| To check for...| Do this...
a|
Broken disks
a|

 .. Display any broken disks: `storage disk show -state broken`
 .. Remove or replace any broken disks.

a|
Disks undergoing maintenance or reconstruction
a|

 .. Display any disks in maintenance, pending, or reconstructing states: `storage disk show -state maintenance\|pending\|reconstructing`
 .. Wait for the maintenance or reconstruction operation to finish before proceeding.
|===

. Verify that all aggregates are online by displaying the state of physical and logical storage, including storage aggregates: `storage aggregate show -state !online`
+
This command displays the aggregates that are _not_ online. All aggregates must be online before and after performing a major upgrade or reversion.
+
----
cluster1::> storage aggregate show -state !online
There are no entries matching your query.
----

. Verify that all volumes are online by displaying any volumes that are _not_ online: `volume show -state !online`
+
All volumes must be online before and after performing a major upgrade or reversion.
+
----
cluster1::> volume show -state !online
There are no entries matching your query.
----

. Verify that there are no inconsistent volumes: `volume show -is-inconsistent true`
+
See the Knowledge Base article link:https://kb.netapp.com/Advice_and_Troubleshooting/Data_Storage_Software/ONTAP_OS/Volume_Showing_WAFL_Inconsistent[Volume Showing WAFL Inconsistent] on how to address the inconsistent volumes.

.Related information

link:../disks-aggregates/index.html[Disk and aggregate management]

== Verify the system time

Before you revert, you should verify that NTP is configured, and that the time is synchronized across the cluster.

. Verify that the cluster is associated with an NTP server: `cluster time-service ntp server show`
. Verify that each node has the same date and time: `cluster date show`
+
----
cluster1::> cluster date show
Node      Date                Timezone
--------- ------------------- -------------------------
node0     4/6/2013 20:54:38   GMT
node1     4/6/2013 20:54:38   GMT
node2     4/6/2013 20:54:38   GMT
node3     4/6/2013 20:54:38   GMT
4 entries were displayed.
----

== Verify that no jobs are running

Before you revert the ONTAP software, you must verify the status of cluster jobs. If any aggregate, volume, NDMP (dump or restore), or Snapshot jobs (such as create, delete, move, modify, replicate, and mount jobs) are running or queued, you must allow the jobs to finish successfully or stop the queued entries.

. Review the list of any running or queued aggregate, volume, or Snapshot jobs: `job show`
+
----
cluster1::> job show
                            Owning
Job ID Name                 Vserver    Node           State
------ -------------------- ---------- -------------- ----------
8629   Vol Reaper           cluster1   -              Queued
       Description: Vol Reaper Job
8630   Certificate Expiry Check
                            cluster1   -              Queued
       Description: Certificate Expiry Check
.
.
.
----

. Delete any running or queued aggregate, volume, or Snapshot copy jobs: `job delete -id job_id`
+
----
cluster1::> job delete -id 8629
----

. Verify that no aggregate, volume, or Snapshot jobs are running or queued: `job show`
+
In this example, all running and queued jobs have been deleted:
+
----
cluster1::> job show
                            Owning
Job ID Name                 Vserver    Node           State
------ -------------------- ---------- -------------- ----------
9944   SnapMirrorDaemon_7_2147484678
                            cluster1   node1          Dormant
       Description: Snapmirror Daemon for 7_2147484678
18377  SnapMirror Service Job
                            cluster1   node0          Dormant
       Description: SnapMirror Service Job
2 entries were displayed
----

// 2022 oct 7, IE-615
// 2022-04-25, BURT 1454366
// 4 Feb 2022, BURT 1451789
